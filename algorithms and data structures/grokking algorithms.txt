При составлении основы конспекта использовалась книга Адитья Бхаргава "Грокаем Алгоритмы".

##############
#    БАЗА    # 
##############
logarithm - противоположен по смыслу возведению в степень. 
	
Примеры:
    Log^10 100 = сколько раз нужно перемножить 10 чтобы получилось 100 ?
    Log^2 N = сколько раз нужно перемножить 2 чтобы получилось N ?

Примечание:
для сокращения записи Log по основанию 2 всегда записывается как просто Log (Log^2 == Log)

O-sintax (О-синтаксис или Order of) - это способ записи оценки сложности алгоритма через указание количества
действий необходимых для достижения результата.

Скорость, немного визуализации, - чем выше по списку, - тем быстрее:
--------------------------------------------------------------------
    Быстро
	O (1) 		- Постоянная зависимость (обращение к элементу массива, простые операторы)
	O (Log N)	- Логарифмическая зависимость (двоичный поиск) 
	O (N)		- Линейная зависимость (последовательный поиск, цикл)
	O (N Log N)	- Эта зависимость слабее линейной, но не намного (среднее время быстрой сортировки, 
			  сортировки методом пузырька)
	O (N^2)		- Квадратичная зависимость (выборочная сортировка и сортировка включением, вложенный цикл)
	O (N^3)		- Кубическая зависимость
    пропасть		- здесь очень большой разрыв в производительности
	O (N!)		- N-факториал (тоже что и C^N)  пример: 5! = 5 x 4 x 3 x 2 x 1 = 120
	O (C^N)		- Экспоненциальная зависимость (задача о коммивояжере, разбиение набора)
    Медленно
--------------------------------------------------------------------
O(N) это на самом деле O(c\*N) где 'с' - это фиксированный промежуток времени

Ещё примеры:
Линейный алгоритм поиска - O (N)
Бинарный алгоритм поиска - O (Log N)
 
	чтение*    вставка(конец)    вставка(середина)    удаление(конец)    удаление(середина)
Array	O(1)       O(1)	       	     O(N)	     	  O(1)	    	     O(N)
List	O(N)       O(1)	       	     O(N)**	     	  O(1)	   	     O(N)**

*  чтение по индексу
** на самом деле O(n) где 'n' это позиция элемента в списке

		чтение    вставка    удаление    поиск
Stack(LIFO)	O(1)	  O(1)	     O(1)	 поиск невозможен


##########################
#    СТРУКТУРЫ ДАННЫХ    #
##########################
По видам доступа структуры деляться на произвольные и последовательные.

-----------------------------------------------
ХЭШ ТАБЛИЦА = Hash Table = хеш-функция + массив
-----------------------------------------------
Хеш-функция - представляет собой функцию, которая получает строку и возвращает число.

Хеш-функция неизменно связывает строку с одним индексом.
Хеш-функция связывает разные строки с разными индексами.
Хеш-функция знает размер массива и возвращает только действитель­ные индексы.

Требования к хеш-функциям:
  1. должна быть последовательной (одну и туже строку всегда преобразовывать в одно и тоже число);
  2. разным словам должны соответствовать разные числа.

В идеале хеш-функция должна распределять ключи равномерно по всему хешу.
В реальности сделать это очень сложно.
Для предотвращения коллизий необходимы:
  1. низкий коэффициент заполнения;
	(0,7 - потолок, если очень низкий - часто пересоздаётся массив, если высокий - мого коллизий;
	коэффициент выше 1 говорит о том, что коллизии абсолютно точно есть)
  2. хорошая хеш-функция.
	(должна обеспечить раномерное распределение)

			 чтение		вставка		удаление
Hash Table (средний)	 O(1)		O(1)	 	O(1)
Hash Table (худший)	 O(N)		O(N)	 	O(N)

-----------------------------------------------
ГРАФЫ ДРАКУЛЫ 
-----------------------------------------------
Каждый граф состоит из узлов и ребер.
Узел может быть напрямую соединен с несколькими другими узлами. Эти узлы называются соседями.
Переменная связанная с ребром называется весом.

Немного о деревьях:
Разновидность графа, в которой нет ребер, указывающих в обратном направлении называется деревом.
Дерево - это граф с ориентированными в одну сторону ребрами
Дерево - подкатегория графов. Дерево всегда граф, но граф не всегда дерево.

Бинарное дерево поиска.
Есть корень - слева то что меньше, справа то, что больше.

	 5
       /   \
      3	    7
     / \   / \
    2   4  6  9
   /	     / \
  1         8  10 
  
поиск, вставка, удаление в реднем за O(log N)  <--- если сбалансировано!

Метод упорядочивания графа - топологическая сортировка.

Алгоритмы поиска для дракул:
- поиск в ширину
- поиск в глубину
- алгоритм дейсктры (для взвешенных графов)
Эти алгоритмы также применимы для решения задачи поиска кратчайшего пути.

Подробнее о поиске в ширину.
  Бинарный поиск (очереди отлично подходят для выполнения бинарного поиска.),
  типы вопросов:
	тип 1: существует ли путь от узла А к узлу В?
	тип 2: как выглядит кратчайший путь от узла А к узлу В?
  Сложность поиска в ширину - O(V+E)
	'V' - это количество вершин 
	'Е' - это количество ребер

Алгоритм Дейкстры - позволяет найти крачйший путь во взвешенном графе.
Алгоритм Дейкстры работает только с направленными ациклическими графами, которые 
				нередко обозначаются сокращением DAG (Directed Acyclic Graph).
Алгоритм Дейкстры также не работает если в графе присутствуют ребра 
				с отрицательным весом (а вот алгоритм Беллмана-Форда с этим справится!)
Алгоритм Дейкстры:
 1. Найти узел с наименьшей стоимостью (то есть узел, до которого можно добраться за минимальное время).
 2. Обновить стоимости соседей этого узла (проверить, существует ли более дешевый путь к соседям этого узла, и, 
 				если существует, обновить их стоимости).
 3. Повторять, пока это не будет сделано для всех узлов графа.
 4. Вычислить итоговый путь (пройдя обратно по родителям).

Реализация алгоритма:

1. нужны три таблицы:
- граф
- стоимости
- родители
2. Массив для отслежевания обработаных узлов 
3. собственно алгоритм:

	Пока остаются необработанные узлы <------
		|				^
		*				|
	Взять узел ближайший к началу		|
		|				|
		*				|
	Обновить стоимости для его соседей	|
		|				|
		*				|
	Если стоимости каких либо узлов 	|
	были обновлены обновить и родителей	|
		|				|
		*				|
	Пометить узел как обработанный --->-----/
	
	
####################
#    СОРТИРОВКИ    #
####################
			Лучший		Худший
Сортировка выбором	О(N^2) но на самом деле ---> N * 1/2 * N
Быстрая сортировка*	О(N log N)	O(N)** 
Сортировка слиянием	О(N log N)	О(N log N)

*  Константа 'c' у быстрой сортировки меньше чем у сортировки слиянием, поэтому быстрая быстрее сортировки слиянием.
** зависит от выбора опорного элемента.


##################
#    РЕКУРСИЯ    #
##################
Чтобы понять рекурсию нужно понять рекурсию.
Ха, забавно! А ведь доказательство по индукции - это рекурсия (базовый случай, индукционный переход).

Каждая рекурсивная функция состоит из двух частей: базового случая и рекурсивного случая.
В рекурсивном случае функция вызывает сама себя. В базовом случае функция себя не вызывает, чтобы предотвратить зацикливание.

Хвостовая рекурсия - частный случай рекурсии, при котором любой рекурсивный вызов является последней операцией перед 
возвратом из функции, то есть за каждым рекурсивным вызовом непосредственно следует операция return.

Пример хвостовой рекурсии (рекурсивный способ сложения 2-х целых чисел):

		static int add(int x, int y) {
		    if (y == 0) return x;
		    return add(x ^ y, (x & y) << 1);
		}
		
Подробнее про хвостовую тут: https://habr.com/ru/post/319282/


##########################
#    ЖАДНЫЕ АЛГОРИТМЫ    #
##########################
Жадные алгоритмы - это алгоритмы в которых на каждом шаге выбирается локально-оптимальное решение, 
а в итоге вы получаете глобально-оптимальное решение.
То есть жадные алгоритмы стремятся к локальной оптимизации в расчете на то, что в итоге будет достигнут глобальный оптимум.
Эти алгоритмы просты в реализации, но не всегда возвращают лучший результат (часто, просто, очень близкий к нему).
Жадные алгоритмы - это приближенные алгоритмы.
Приближенный алгоритм - это алгоритм, который находит решение близкое к оптимальному, и лишь иногда оптимальное.

Такие "приближенные алгоритмы" оцениваются по:
  1. быстроте;
  2. близости полученного решения к оптимальному.

Жадные алгоритмы используются при решении NP-полных задач.

NP-полная задача — в теории алгоритмов задача с ответом «да» или «нет» из класса NP, к которой можно свести любую другую 
задачу из этого класса за полиномиальное время (то есть при помощи операций, число которых не превышает некоторого полинома
в зависимости от размера исходных данных).

В теории алгоритмов классом NP (от англ. non-deterministic polynomial) называют множество проблем разрешимости, решение
которых возможно проверить на машине Тьюринга за время, не превосходящее полинома от размера входных данных, при наличии 
некоторых дополнительных сведений (так называемого сертификата решения).

Задача разрешимости (проблема разрешимости) — вопрос, сформулированный в рамках какой-либо формальной системы, требующий 
ответа «да» или «нет», возможно, зависящего от значений некоторых входных параметров.

Классические примеры NP-полных задач: Задача о коммивояжере и задача о покрытии множества.


#######################################
#    ДИНАМИЧЕСКОЕ ПРОГРАММИРОВАНИЕ    #
#######################################
Простым языкам - это решение большой задачи через множество подзадач

Задача о рюкзаке коротко: есть рекзак определённого объёма, есть набор вещей разного объема, сумма объемов этих вещей 
больше объема рюкзака, цель - наполнить рюкзак таким набором вещей суммарный оъем которых будет максимально приближен или 
равен объему рюкзак.

Алгоритм решения задачи о рюкзаке:
Мы формируем таблицу - где горизонтали соответствуют доступным предметам, а вертикали - возможным размерам ёмкости.
Хотим посмотреть как решается задача шаг за шагом: для самого маленького рюкзака, потом, 
для чуть большего и т.д. - это и есть динамический алгоритм.

Шаг зависит от характеристик объекта. Необходимо выбрать шаг с лучшим приближением.

  cell 	- клетка таблицы
  i 	- строка
  j 	- столбец

cell[i][j] = максимум = предыдущий максимум cell[i-1][j] || стоимость текущего элемента  + 
	стоимость оставшегося пространства cell[i-1][j - вес предмета]
Короткая запись:
cell[i][j] = cell[i-1][j] || i.стоимость  + cell[i-1][j - вес предмета]

Динамическое программирование работает толъко в том случае, если каждая подзадача автономна, то естъ не зависит от других подзадач.


#########################################
#    АЛГОРИТМ 'К'* БЛИЖАЙШИХ СОСЕДЕЙ    #
#########################################
*для 'K' объектов следует рассматривать sqrt(K) соседей.

Алгоритм K ближайших соседей - это алгоритм использующийся для классификации сущностей на основе характеристик соседних сущностей в множестве.

--------------------------------------------------------------------------------
Собственно алгоритм:
1)
Мы выделяем множество характеристик (критерии).
Важно правильно выбрать критерии:
 - непосредственно относятся к предмету работы
 - не содержат смещения (не должно быть воброса по критерию)
Объекты обладающие этими критерии мы наносим на сеть координат (где кол-во измерений равно кол-ву характеристик).

2)
Высчисляем расстояние между объектами.
Растояние между объектами измеряется по формуле Пифигора! (часто ещё применяется 'метрика близости косинусов')

Для двух точек:
Корень{ (x1-x2)^2 + (y1-y2)^2 }

Для трех точек:
Корень{ (x1-x2)^2 + (y1-y2)^2 + (z1-z2)^2 }

Для множества точек:
Корень{ (x1-x2)^2 + (y1-y2)^2 + ... + (n1-n2)^2 }

3)
Формируем ответ на основе количества и расстояния до ближайших соседей.
--------------------------------------------------------------------------------

Для чего применяют алгоритм K ближайших соседей?
  1. классификация = распределение по категориям
  2. регрессия* = прогнозирование ответа (в числовом выражении)
  3. лежит в основе некоторых алгоритмов машинного обучения
  4. спам фильтры... etc, в действительности областей применения масса!

*R - регрессия.
Регрессия - метод построения критерия на основе уже построенных критериев ближайших соседей.

Простой пример машинного обучения:
- тренировка (выделение критериев)
- работа (алгоритм K ближайших соседей (классификация))

Наивный классификатор Байеса (спам фильтры).

	Тренировка:
	ТЕМА						СПАМ?
	измените пароль					нет
	вы выиграли миллион				да
	сообщите свой пароль				да
	нигирийских принц готов перевести вам миллион	да	
	с днем рождения					нет

	Во время тренировка смотрим какие слова есть и как часто они встречаются в спаме и не в спаме.
	Например слово миллион - определённо маркер спама

	Работа:
	Применяем алгоритм K ближайших соседей.


#########################################################
#    НА БУДУЩЕЕ (ЧТО ЕЩЁ ПОСМОТРЕТЬ, О ЧЁМ ПОЧИТАТЬ)    #
#########################################################
---> Инвертированные индексы <---
это хеш-таблица, связывающая слова с местами, в которых эти слова встречаются.
Отлично подходит для поиска данных.

---> Преобразование Фурье <---
Если у вас есть коктейль , преобразование Фурье сообщает, из каких ингредиентов он состоит.
Если у вас есть песня, преобразовани Фурье реразделяет ее на отдельные частоты.

---> Парралельные алгоритмы <---
MapReduce - распределенный алгоритм (работаем с множеством машин и ядер).
В основе технологии MapReduce лежат две простые идеи:
 - функция отображения map (преобразует каждый отдельный элемент)
 - функция свертки reduce (преобразует весь набор элементов)

---> Фильтры Блума и Hyperloglog <---
Фильтр блума - вероятностная структура данных.
Возможны ложно-положительные ответы, ложно-отрицательные ответы исключены (если да, то может быть и нет, но если нет, то нет).
HyperLogLog аппроксимирует количество уникальных элементов в множестве.

---> Алгоритмы SHA <---
SHA (Secure Hash Algorithm)- разновидность хеш-функций
Преобразует строку в строку.
Локально чувствительные алгоритмы - обратимые хеш функции
Simhash - используется для сравнения строк (антиплагиат)

---> Обмен ключами Диффи-Хеллмана <---
И его наследник - RSA
Комбинирование открытого и закрытого ключа для шифрования.

---> Линейное программирование <---
Это что-то очень крутое.. )
Линейное программирование используется для максимизации некоторой характеристики при заданных ограничениях.
В линейном программировании используется симплекс-метод.











