О системе.
Библиотека программного обеспечения Apache Hadoop представляет собой структуру, которая позволяет организовать распределенную обработку
больших наборов данных в кластерах компьютеров с использованием простых моделей программирования. Она предназначена для масштабирования
на уровне как отдельных серверов, так и систем в которые входят тысячи компьютеров (каждый из которых предлагает локальные вычисления
и хранение). 
Вместо того, чтобы полагаться на аппаратное обеспечение для обеспечения высокой доступности, сама библиотека ориентирована 
на обнаружение и обработку сбоев на уровне приложений через предоставление высокодоступного сервиса поверх кластера компьютеров.

Проект включает в себя следующие модули:
  Hadoop Common     - общие утилиты, поддерживающие другие модули Hadoop.
  Hadoop HDFS       - распределенная файловая система, обеспечивающая высокопроизводительный доступ к данным приложения.
  Hadoop YARN       - структура планирования рабочих мест и управления ресурсами кластера.
  Hadoop MapReduce  - система на основе YARN для параллельной обработки больших наборов данных.

Другие проекты, связанные с Hadoop:
  Ambari    - веб-инструмент для создания, управления и мониторинга кластеров Apache Hadoop, который включает поддержку Hadoop HDFS,
              Hadoop MapReduce, Hive, HCatalog, HBase, ZooKeeper, Oozie, Pig и Sqoop. 
              Ambari также предоставляет панель мониторинга состояния кластера (карты тепла, а также возможность визуально просматривать
              приложения), MapReduce, Pig и Hive вместе с функциями для диагностики их характеристик производительности в удобной для
              пользователя форме;
  Avro      - система сериализации данных;
  Cassandra - масштабируемая база данных с несколькими мастерами без каких-либо точек отказа;
  Chukwa    - система сбора данных для управления большими распределенными системами;
  HBase     - масштабируемая распределенная база данных, которая поддерживает структурированное хранение данных для больших таблиц.
  Hive      - инфраструктура хранилища данных, которая обеспечивает сводку данных и обеспечивает организацию рабос со 
              специальными запросами;
  Mahout    - масштабируемая компьютерная библиотека обучения и обработки данных;
  Pig       - высокоуровневый язык потока данных и среда выполнения для параллельных вычислений;
  Spark     - быстрый и общий вычислительный движок для данных Hadoop;
              Spark обеспечивает простую и выразительную модель программирования, которая поддерживает широкий спектр приложений,
              включая ETL, машинное обучение, обработку потока и вычисление графа;
  Tez       - обобщенная структура программирования потока данных, построенная на Hadoop YARN, которая обеспечивает мощный и гибкий
              механизм для выполнения произвольноых DAG задач для обработки данных (как для пакетных, так и для интерактивных
              прецедентов). Tez работает с Hive, Pig и другими системами экосистемы Hadoop, а также другим коммерческим 
              программным обеспечением (например, инструментами ETL) для замены Hadoop MapReduce в качестве основного
              механизма выполнения;
  ZooKeeper - высокопроизводительная служба координации для распределенных приложений.

https://www.youtube.com/watch?v=Rr-tBaFPEZY
https://www.youtube.com/watch?v=1MK_CzeeAP8
https://www.youtube.com/watch?v=3h-1Nl3eLQ0&list=PLwwk4BHih4fgJxD7b_hMWfNxVyFLObU5U

Для работы с ZK используй ZooInspector!
