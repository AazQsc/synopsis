ОБЩАЯ ИНФОРМАЦИЯ

При проектировании работы кэша следует уделить внимание следующим вопросам:

1. какие данные мы храним в кэше?

2. какую стратегию кэширования будем использовать?

	Типы кешей по выпранной стратегии:
	- lazy cache - самая простая, сохраняем данные и отдаём их пока они не устареют
	- Synchronized cache - клиент вместе с данными получает метку последнего изменения 
	  и может спросить у поставщика не изменились ли данные, чтобы повторно их не запрашивать
	- Write-through cache - любое изменение данных выполняется сразу и в хранилище и в кэше
	
3. Вопрос об инвалидации кэша - как мы выселяем данные из кэша (политика выселения)?

	Алгоритмы (ctrl+c\v с википедии):
	
	- Алгоритм Белади
	  Наиболее эффективное правило вытеснения — отбрасывать из кэша ту информацию, которая не понадобится в будущем дольше всего. 
	  Ещё его называют алгоритмом предвидения. Но так как в общем случае невозможно предсказать, когда именно в следующий раз 
	  потребуется именно эта информация, то на практике (опять же, в общем случае) подобная реализация невозможна.
	  Практический минимум может быть вычислен только опытным путём, после чего можно сравнить с ним эффективность текущего 
	  алгоритма кэширования.
	  
	- Least recently used (LRU)(Вытеснение давно неиспользуемых)
	  В первую очередь, вытесняется неиспользованный дольше всех. Этот алгоритм требует отслеживания того, что и когда 
	  использовалось, что может оказаться довольно накладно, особенно если нужно проводить дополнительную проверку, 
	  чтобы в этом убедиться. 
	  
	- Most Recently Used (MRU)(Наиболее недавно использовавшийся)
	  В отличие от LRU, в первую очередь вытесняется последний использованный элемент. 
	  Когда файл периодически сканируется по циклической схеме, MRU — наилучший алгоритм вытеснения. L
	  Для схем произвольного доступа и циклического сканирования больших наборов данных (иногда называемых схемами 
	  циклического доступа) алгоритмы кэширования MRU имеют больше попаданий по сравнению с LRU за счет 
	  их стремления к сохранению старых данных. Алгоритмы MRU наиболее полезны в случаях, когда чем старше элемент, 
	  тем больше обращений к нему происходит.
	
	- Псевдо-LRU (PLRU)
	  Для кэшей с большой ассоциативностью (обычно > 4 каналов), цена реализации LRU становится непомерно высока. 
	  Если достаточна схема, что почти всегда нужно отбрасывать наименее используемый элемент, то в этом случае можно использовать
	  алгоритм PLRU, требующий для элемента кэша только один бит.
	  
	- Сегментированный LRU (Segmented LRU или SLRU)
	  SLRU-кэш делится на два сегмента. пробный сегмент и защищенный сегмент. 
	  Строки в каждом сегменте упорядочены от частоиспользуемых к наименее используемым. 
	  Данные при промахах добавляются в кэш, причем в область последних использованных элементов пробного сегмента. 
	  Данные при попаданиях убираются где бы они не располагались и добавляются в область частоиспользуемых элементов 
	  защищенного сегмента. К строкам защищенного сегмента обращения таким образом происходят по крайней мере дважды. 
	  Защищенный сегмент ограничен. Такой перенос строки из пробного сегмента в защищенный сегмент может вызвать перенос 
	  последней использованной (LRU) строки в защищенном сегменте в MRU-область пробного сегмента, давая этой линии второй 
	  шанс быть использованной перед вытеснением. Размер защищенного сегмента — SLRU-параметр, который меняется в зависимости 
	  от схемы работы ввода-вывода. Всякий раз когда данные должны быть вытеснены из кэша, строки запрашиваются из LRU-конца 
	  пробного сегмента.
	  
	- 2-Way Set Associative (2-канальная ассоциативность)
	  Применяется для высокоскоростного процессорного кэша, где даже PLRU слишком медленен. 
	  Адрес нового элемента используется для вычисления одного из двух возможных местонахождений в кэше (в отведенной для этого
	  области). По алгоритму LRU два элемента вытесняются.
	
	- Кэш прямого отображения (Direct-mapped cache)
	  Для высокоскоростных кэшей процессора, где не хватает быстродействия 2-канального ассоциативного кэширования. 
	  Адрес нового элемента используется для вычисления местонахождения в кэше (в отведенной для этого области). 
	  Все, что было ранее, — вытесняется.
	
	- Least-Frequently Used (LFU)(Наименее часто используемый)
	  LFU подсчитывает как часто используется элемент. Те элементы, обращения к которым происходят реже всего, 
	  вытесняются в первую очередь.
	
	- Adaptive Replacement Cache (ARC)(Адаптивная замена)
	  Постоянно балансирует между LRU и LFU, что улучшает итоговый результат.
	
	- Multi Queue Caching Algorithm (MQ)(Алгоритм многопоточного кэширования)
	  Учитываются следующие моменты:
		1. Элементы с различной стоимостью: хранение элементов, запрос которых весьма дорог, например, такие, 
		   получение которых затребует много времени.
		2. Элементы, требующие больше места в кэше: если элементы имеют разный размер, то кэш может попытаться вытеснить 
		   больший элемент, чтобы сохранить несколько элементов поменьше.
		3. Элементы, устаревающие с течением времени: Некоторые кэши хранят устаревающую информацию (например, 
		   кэш новостей, DNS-кэш или кэш веб-браузера). Компьютер может вытеснить элементы вследствие их устаревания. 
		   В зависимости от размера кэша, кэширование новых элементов может потребовать вытеснение старых.

	Используя эти алгоритмы данные в кеше можно не только удалять но обновлять.
	Можно единовременно использовать один из алгоритмов для обновления данных, а другой для удаления.
	Алгоритмы можно комбинировать.

4. Какой будет размер у кэша?

5. Нужно ли заботится о когерентности?
 	Механизмы когерентности кешей:
	- Когерентность с использованием справочника (directory). Информация о состоянии блока физической памяти содержится 
	  только в одном месте, называемом справочником (физически справочник может быть распределен по узлам системы).
	- Когерентность с использованием отслеживания (snooping). Каждый кэш, который содержит копию данных некоторого 
	  блока физической памяти, имеет также соответствующую копию служебной информации о его состоянии. 
	  Централизованная система записей отсутствует. Обычно кэши расположены на общей (разделяемой) шине и контроллеры 
	  всех кэшей наблюдают за шиной (просматривают её) для определения того, не содержат ли они копию соответствующего блока.
	- Перехват (snarfing). Когда из какого-либо одного кэша данные переписываются в оперативную память, 
	  контроллеры остальных получают сигнал об этом изменении ("перехватывают" информацию об изменении данных) и, 
	  если необходимо, изменяют соответствующие данные в своих кэшах


КЕШИ
---------------------------------------------------------------------------------------
1. Google's Guava library (Caches)

	Добавляет коллекции Cache и LoadingCache
	У этих коллекций есть методы которые позволяют задать размер,
	который может занимать коллекция в оперативной памяти.

	Также можно указать время существования объекта в памяти.
	Возможно есть поддержка других стратегий инвалидации.

	LoadingCache<Key, Graph> graphs = CacheBuilder.newBuilder()
    		.maximumSize(1000)
		.expireAfterWrite(10, TimeUnit.MINUTES)


	- Ссылка на библиотеку, есть примеры:
	https://github.com/google/guava/wiki/CachesExplained

	- 5-минутное видео с примером: 
	https://vimore.org/watch/ikRVbAGQBhA/guava/

	- Как автоматически обновлять кеш с помощью Google Guava? (оригинальна ссылка будет на sof):
	http://qaru.site/questions/325630/how-to-automatically-refresh-cache-using-google-guava

---------------------------------------------------------------------------------------
2. ehcache

	Есть несколько объектов
	 Configuration() 
	  Один из методов конфигурации позволяет указать место на физ носителе куда будет записываться кеш
	  Configuration().path("/path/to/store/data"));

	 CacheConfiguration()
	 .maxBytesLocalHeap(16, MemoryUnit.MEGABYTES)     //размер кэша
    	 .maxBytesLocalOffHeap(256, MemoryUnit.MEGABYTES)

	 Ehcache cache = cacheManager.getEhcache("myCache");
	  cache.put(new Element());
	  cache.put(new Element());

	- Документация
	http://www.ehcache.org/documentation/3.4/writers.html 

	- статья "Распределённая система кеша ehcache для приложений любого уровня"
	https://habrahabr.ru/post/25140/

	- Небольшой Пример
	https://ru.stackoverflow.com/questions/644690/

	- Интеграция Ehcache и Spring 3.1:
	http://www.javacore.ru/topic/86-ehcache-spring.htm 

	- Сравнение ehcache и hazelcast 
	Осторожно, плохой перевод (оригинал на sof)!
	http://qaru.site/questions/105845/hazelcast-vs-ehcache 

---------------------------------------------------------------------------------------
3. hazelcast

	Это распределённое хранилище объектов,
 	- по ссылке можно найти много хороших примеров.
	https://hazelcast.org

	- Виктор Гамов, Hazelcast — Распределяй и властвуй: введение в распределенные системы
	https://www.youtube.com/watch?v=J68pBDicGII

	- Запускаем кластер Hazelcast 3.1 на платформe Jelastic в InfoboxCloud
	https://infoboxcloud.ru/community/blog/in_memory_data_grid/14.html

	- Статья: Что, если выкинуть все лишнее из базы в распределенный кэш – наш опыт использования Hazelcast
	https://habrahabr.ru/company/yamoney/blog/332462/ https://www.youtube.com/watch?v=iMJmA31hBlE 


================================================================================
Доп. информация:

	- Просто любопытная статья, тема кешей хорошо проиллюстрирована 
	https://dev.by/lenta/main/pochemu-realizatsiya-bolshogo-kesha-dannyh-na-net-i-java-ne-ochen-horoshaya-ideya

	- Тут можно найти ещё упоминаний о том, какие библиотеки для кеширования есть:
	http://qaru.site/questions/61150/lightweight-java-object-cache-api
	https://stackoverflow.com/questions/575685/looking-for-simple-java-in-memory-cache 

	- Статья: Почему реализация большого кэша данных на .net и java - не очень хорошая идея?
	https://dev.by/lenta/main/pochemu-realizatsiya-bolshogo-kesha-dannyh-na-net-i-java-ne-ochen-horoshaya-ideya

	- Часто можно встретить ссылки на JCS 
	Это спецификация описывающая способы кеширования которые в принципе есть в джава 
	Но это не совсем подходит под вопрос. Но там можно найти много любопытной информации
	https://commons.apache.org/proper/commons-jcs/
	https://commons.apache.org/proper/commons-jcs/commons-jcs-core/apidocs/org/apache/commons/jcs/JCS.html


